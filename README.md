# ğŸš€ My Big Data Learning Journey

Welcome to my personal learning journey into the world of **Big Data**, where I'm diving deep into **SQL, Python, GCP, Azure**, and various **data engineering concepts**. I'm documenting everything I learn, practice, and build â€” one day at a time.

---

## ğŸ—“ï¸ Daily Learning Progress

### âœ… **Day 1 â€“ Introduction to Big Data Engineering**
- Understood the role and responsibilities of a Big Data Engineer.
- Explored real-world use cases.
- Set up my learning goals and plan.

### âœ… **Day 2 â€“ SQL Basics**
- Created databases and tables.
- Inserted, updated, and deleted records.
- Practiced DML operations and table alterations.

### âœ… **Day 3 â€“ Constraints and Indexes**
- Learned about Primary Key, Foreign Key, Unique, Not Null, and Check constraints.
- Explored Indexing and Candidate Keys.

### âœ… **Day 4 â€“ SQL Joins**
- Practiced INNER, LEFT, RIGHT, FULL OUTER, and CROSS JOINs.
- Understood data relationships and merging tables.

### âœ… **Day 5 â€“ Subqueries**
- Worked with single-row, multi-row, nested, and correlated subqueries.
- Learned how subqueries can solve complex logic within SQL.

### âœ… **Day 6 â€“ Common Table Expressions (CTEs)**
- Simplified queries using CTEs.
- Explored recursive CTEs for hierarchical data.

### âœ… **Day 7 â€“ Window Functions**
- Practiced ROW_NUMBER(), RANK(), DENSE_RANK().
- Used PARTITION BY and ORDER BY within the OVER() clause.

### âœ… **Day 8 â€“ Python Revision Begins**
- Reviewed Python basics: syntax, variables, data types, loops, conditionals, functions, and collections (lists, tuples, sets, dictionaries).
- Code and notes uploaded in this repository.

âœ… **Day 9 â€“ Python Functional Programming & File Handling**
- Learned Lambda functions, `map()`, and `filter()` for cleaner and faster operations.
- Explored Python modules, the standard library, and importing techniques.
- Practiced file operations: reading, writing, and working with file paths.
- Understood and implemented exception handling to build error-resilient programs.
- Code and examples added to the repository.

âœ… **Day 10 â€“ Object-Oriented Programming in Python**
- Revised and practiced key OOP concepts to improve code structure and reusability.
- Topics covered:
  - **Classes & Objects** â€“ The foundation of OOP in Python.
  - **Inheritance** â€“ Reusing code through parent-child class structures.
  - **Polymorphism** â€“ Allowing methods to behave differently depending on the object.
  - **Encapsulation** â€“ Keeping data secure and private within objects.
  - **Abstraction** â€“ Hiding internal implementation and exposing only necessary parts.

âœ… **Day 11 â€“ Magic Methods, Iterators & Decorators**
- Explored advanced Python concepts to write more Pythonic, powerful, and reusable code.
- Topics covered:
  - Magic Methods (`__str__`, `__repr__`, `__add__`, etc.)
  - Custom Exceptions
  - Operator Overloading
  - Iterators & Iterables
  - Generators using `yield`
  - Function Decorators

âœ… **Day 12 â€“ Python Libraries for Data Handling & Integration**
- Focused on real-world data manipulation and connecting Python to databases.
- Topics covered:
  - NumPy â€“ Arrays and numerical operations
  - Pandas â€“ DataFrames, cleaning, filtering, and reshaping data
  - Data Cleaning â€“ Handling nulls, duplicates, formatting
  - Logging â€“ Structured logging and debugging
  - SQLite with Python â€“ Creating DBs, inserting records, querying with `sqlite3`

âœ… **Day 13 â€“ Introduction to Big Data Concepts**
- Learned the foundational concepts of Big Data and modern system architecture.
- Topics covered:
  - What is Big Data â€“ Real-world example
  - 5 V's of Big Data â€“ Volume, Velocity, Variety, Veracity, Value
  - Distributed Systems â€“ Why and how we scale
  - Designing a Good Big Data System â€“ Best practices
  - On-Premise vs Cloud Infrastructure
  - Database vs Data Warehouse vs Data Lake
  - ETL vs ELT â€“ Understanding transformation flow.
  
âœ… **Day 14 â€“ Hadoop Architecture & Ecosystem**
- Learned the core fundamentals of Hadoop and its role in distributed data processing.
- Topics covered:
  - Hadoop Architecture: GFS, MapReduce
  - Hadoop Properties: Scalability, Fault Tolerance, Distributed Processing, Cost-Effectiveness, Open Source
  - HDFS (Hadoop Distributed File System): File system blocks, replication, rack awareness, metadata handling
  - Hadoop Ecosystem Overview:
    - **Storage**: HDFS, HBase
    - **Processing**: MapReduce, Pig, Hive, Spark
    - **Data Integration**: Flume, Sqoop
    - **Workflow & Coordination**: Oozie, ZooKeeper
    - **ML**: Mahout

âœ… **Day 15 â€“ GCP Cluster Setup & DataNode Failures**
- Took the first step into cloud platforms by creating a cluster on Google Cloud Platform (GCP).
- Topics covered:
  - GCP setup: Compute Engine, firewall rules, SSH configuration
  - Created a basic Hadoop cluster on virtual machines
  - Learned how Hadoop handles **DataNode failures**:
    - Temporary vs Permanent failure
    - Heartbeat mechanism & block replication
    - HDFS fault-tolerant architecture
