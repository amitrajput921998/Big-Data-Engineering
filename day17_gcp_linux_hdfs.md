# üåê Day 17 ‚Äì GCP Hadoop Cluster, Linux & HDFS Command Practice

## ‚úÖ GCP Cluster Creation
- Created VMs using Compute Engine
- SSH access setup & Hadoop installation
- Configured cluster nodes (NameNode, DataNode)
- Configured security rules (firewall ports: 50070, 9000)

## ‚úÖ Exploring the Cluster
- Verified Hadoop processes and UI dashboards
- Navigated between cluster machines using SSH
- Checked log files and configuration files

## ‚úÖ GCP Best Practices (Quick Notes)
- Always restrict firewall access
- Use startup scripts for automation
- Monitor disk usage and region zones
- Use metadata tags to organize resources

---

## ‚úÖ Linux Commands Practice
- File navigation: `ls`, `cd`, `pwd`, `cat`, `more`
- File manipulation: `cp`, `mv`, `rm`, `touch`, `nano`, `chmod`
- System info: `top`, `ps`, `df -h`, `free -m`
- Directory ops: `mkdir`, `rmdir`, `tree`
- User & permissions: `chmod`, `chown`, `su`, `sudo`

---

## ‚úÖ HDFS Commands Practiced
- File operations:
  - `hdfs fs -ls /`
  - `hdfs fs -mkdir /data`
  - `hdfs fs -put localfile.txt /data`
  - `hdfs fs -cat /data/localfile.txt`
  - `hdfs fs -rm /data/localfile.txt`
- Permissions and block checking:
  - `hdfs fs -chmod 755 /data`
  - `hdfs fsck /data -files -blocks -locations`


